# train_file: ['/home/zhuhg/dataset/product1M/json/train_id_info.json']
# test_file: '/home/zhuhg/dataset/product1M/json/query_id_info.json'  
# image_root: '/home/zhuhg/dataset/product1M/train_images'
# test_image_root: '/home/zhuhg/dataset/product1M/test_images'
# train_file: ['/home/zhuhg/dataset/M5product/M5Product-dataset/product5m_train_id_label_new.json']
#train_file: '/data3/datasets/m5_subset/train_2w.lmdb' #['/data6/xl/multi_modal/data/product5m_v2/subset_v2_id_label.json'] #['/home/zhuhg/dataset/M5product/M5Product-dataset/product5m_test_id_label_new.json']
#test_file: '/data6/xl/multi_modal/data/product5m_v2/subset_v2_id_label.json' #'/data3/datasets/m5_subset/train_2w.lmdb' #['/data6/xl/multi_modal/data/product5m_v2/subset_v2_id_label.json'] #'/home/zhuhg/dataset/product1M/json/query_id_info.json'
# image_root: '/home/zhuhg/dataset/M5product/data3/train_images'
train_file: ['/mnt/data/yangzhenbang/BLIP/annotation/coco_karpathy_train_pretrain.json',
             '/mnt/data/yangzhenbang/BLIP/annotation/vg_caption.json',
             ]
cc3m_file: ['/data2/datasets/cc3m/cc3m_new.json',
             ]
#train_file: ['/data1/yangzhenbang_new/blip/BLIP/annotation/coco_karpathy_train_pretrain.json',
#             ]
#image_root: '/data5/DX_SCALE_grad_model/test_tmp_imag/test_img' #'/home/zhuhg/dataset/M5product/data3/test_images'
## '/home/zhuhg/dataset/M5product/data3/test_images'
#test_image_root: '/data5/DX_SCALE_grad_model/test_tmp_imag/test_img' #'/home/zhuhg/dataset/product1M/test_images'
laion_path: ''
cc3m_path: '/data2/datasets/cc3m/images'
#dataset: 'product'

# size of vit model; base or large
vit: 'base'
vit_grad_ckpt: False
vit_ckpt_layer: 0

image_size: 224
batch_size_train: 48
batch_size_test: 4

# optimizer
weight_decay: 0.05
init_lr: 2e-4
min_lr: 1e-6
warmup_lr: 1e-6
lr_decay_rate: 0.9
max_epoch: 10
warmup_steps: 3000

k_test: 128

max_len: 30
